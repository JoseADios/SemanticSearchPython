# ğŸŒŸ Proyecto Final: Sistema de BÃºsqueda SemÃ¡ntica para ArtÃ­culos CientÃ­ficos

## ğŸ“š IntroducciÃ³n

Este proyecto implementa un sistema de bÃºsqueda semÃ¡ntica para artÃ­culos cientÃ­ficos utilizando el dataset de arXiv. El sistema permite realizar consultas en lenguaje natural y obtener los artÃ­culos mÃ¡s relevantes basados en la similitud de embeddings generados por un modelo de lenguaje preentrenado. AdemÃ¡s, se incluyen mÃ©tricas para evaluar la calidad de las bÃºsquedas y se visualizan los embeddings utilizando PCA.

## ğŸ› ï¸ Instrucciones de instalaciÃ³n

### Prerrequisitos

1. ğŸ Python 3.6 o superior
2. ğŸ”‘ Una cuenta en Kaggle para descargar el dataset de arXiv
3. ğŸ“ Google Colab (opcional, pero recomendado)

### InstalaciÃ³n

1. Clonar el repositorio:
    ```bash
    git clone <URL_DEL_REPOSITORIO>
    cd <NOMBRE_DEL_REPOSITORIO>
    ```

2. Instalar las dependencias necesarias:
    ```bash
    pip install -r requirements.txt
    ```

3. Descargar el dataset de arXiv desde Kaggle en Google Colab:
    ```python
    from google.colab import userdata
    userdata.get('KAGGLE_API_KEY')

    !mkdir ~/.kaggle
    !echo userdata.get('KAGGLE_API_KEY') > ~/.kaggle/kaggle.json
    !chmod 600 ~/.kaggle/kaggle.json
    !kaggle datasets download -d Cornell-University/arxiv
    !echo "Y" | unzip arxiv.zip
    ```

## ğŸ“– GuÃ­a de uso

1. Abre el notebook `notebook.ipynb` en Google Colab o en tu entorno de Jupyter Notebook preferido.

2. Ejecuta cada celda del notebook en orden. El cÃ³digo estÃ¡ dividido en las siguientes secciones:
    - **RecolecciÃ³n de Datos**: Descarga y carga del dataset de arXiv.
    - **Preprocesamiento**: Limpieza y normalizaciÃ³n del texto, y tokenizaciÃ³n de los artÃ­culos.
    - **GeneraciÃ³n de Embeddings**: Uso de un modelo preentrenado para generar embeddings de los artÃ­culos.
    - **BÃºsqueda SemÃ¡ntica**: ImplementaciÃ³n de una funciÃ³n de bÃºsqueda que utiliza similitud coseno para encontrar los artÃ­culos mÃ¡s relevantes.
    - **VisualizaciÃ³n**: Uso de PCA para reducir la dimensionalidad de los embeddings y visualizarlos en 2D y 3D.

3. Para realizar una bÃºsqueda, modifica la variable `query` en la celda correspondiente y ejecuta la celda para ver los resultados.

4. Incluye mÃ©tricas para evaluar la calidad de las bÃºsquedas, como precisiÃ³n y recuperaciÃ³n, y realiza pruebas con diferentes consultas para demostrar la efectividad del sistema.

## ğŸ“‚ Carpeta `data`

La carpeta `data` contiene un fragmento del dataset para facilitar pruebas y desarrollo. AsegÃºrate de cargar este fragmento en tu entorno de trabajo para ejecutar el notebook si no deseas descargar el dataset completo.

## ğŸ”— Enlace al notebook en Google Colab

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JoseADios/SemanticSearchPython/blob/main/SemanticSearch.ipynb)

## ğŸ¥ Enlace al video explicativo

[Enlace al video](https://drive.google.com/file/d/19G0y2eF87CUkK0CcZR_EhdTF2H2NJFHP/view?usp=sharing)

---

Este proyecto fue desarrollado como parte del curso de Inteligencia Artificial, dirigido por el Profesor Lizandro RamÃ­rez.
